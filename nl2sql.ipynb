{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.utilities import SQLDatabase\n",
    "db = SQLDatabase.from_uri(\"postgresql://postgres:642000@localhost:5432/test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "llmoai = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.agent_toolkits import SQLDatabaseToolkit\n",
    "from langchain_groq import ChatGroq\n",
    "\n",
    "toolkit = SQLDatabaseToolkit(db=db, llm=ChatGroq(model='llama-3.1-70b-versatile'))\n",
    "tools = toolkit.get_tools()\n",
    "\n",
    "tables_tool = next(tool for tool in tools if tool.name == \"sql_db_list_tables\")\n",
    "schema_tool = next(tool for tool in tools if tool.name == \"sql_db_schema\")\n",
    "query_tool = next(tool for tool in tools if tool.name == \"sql_db_query\")\n",
    "checker_tool = next(tool for tool in tools if tool.name == \"sql_db_query_checker\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[QuerySQLDataBaseTool(description=\"Input to this tool is a detailed and correct SQL query, output is a result from the database. If the query is not correct, an error message will be returned. If an error is returned, rewrite the query, check the query, and try again. If you encounter an issue with Unknown column 'xxxx' in 'field list', use sql_db_schema to query the correct table fields.\", db=<langchain_community.utilities.sql_database.SQLDatabase object at 0x0000021DA38A9730>),\n",
       " InfoSQLDatabaseTool(description='Input to this tool is a comma-separated list of tables, output is the schema and sample rows for those tables. Be sure that the tables actually exist by calling sql_db_list_tables first! Example Input: table1, table2, table3', db=<langchain_community.utilities.sql_database.SQLDatabase object at 0x0000021DA38A9730>),\n",
       " ListSQLDatabaseTool(db=<langchain_community.utilities.sql_database.SQLDatabase object at 0x0000021DA38A9730>),\n",
       " QuerySQLCheckerTool(description='Use this tool to double check if your query is correct before executing it. Always use this tool before executing a query with sql_db_query!', db=<langchain_community.utilities.sql_database.SQLDatabase object at 0x0000021DA38A9730>, llm=ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x0000021DB5B874A0>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x0000021DB5CE2840>, model_name='llama-3.1-70b-versatile', model_kwargs={}, groq_api_key=SecretStr('**********')), llm_chain=LLMChain(verbose=False, prompt=PromptTemplate(input_variables=['dialect', 'query'], input_types={}, partial_variables={}, template='\\n{query}\\nDouble check the {dialect} query above for common mistakes, including:\\n- Using NOT IN with NULL values\\n- Using UNION when UNION ALL should have been used\\n- Using BETWEEN for exclusive ranges\\n- Data type mismatch in predicates\\n- Properly quoting identifiers\\n- Using the correct number of arguments for functions\\n- Casting to the correct data type\\n- Using the proper columns for joins\\n\\nIf there are any of the above mistakes, rewrite the query. If there are no mistakes, just reproduce the original query.\\n\\nOutput the final SQL query only.\\n\\nSQL Query: '), llm=ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x0000021DB5B874A0>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x0000021DB5CE2840>, model_name='llama-3.1-70b-versatile', model_kwargs={}, groq_api_key=SecretStr('**********')), output_parser=StrOutputParser(), llm_kwargs={}))]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [tables_tool, schema_tool]\n",
    "llm = llmoai.bind_tools(tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"\"\"You are helpful assitant who retrieves the schemas and demo data of tables relevant to the query from a postgresql database \n",
    "               using the tables and schema tool. \n",
    "               Do not write the SQL queries just retrieve the schemas and demo data.\n",
    "            \"\"\",\n",
    "        ),\n",
    "        (\"user\", \"{input}\"),\n",
    "        MessagesPlaceholder(variable_name=\"agent_scratchpad\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents.format_scratchpad.openai_tools import (\n",
    "    format_to_openai_tool_messages,\n",
    ")\n",
    "from langchain.agents.output_parsers.openai_tools import OpenAIToolsAgentOutputParser\n",
    "\n",
    "agent = (\n",
    "    {\n",
    "        \"input\": lambda x: x[\"input\"],\n",
    "        \"agent_scratchpad\": lambda x: format_to_openai_tool_messages(\n",
    "            x[\"intermediate_steps\"]\n",
    "        ),\n",
    "    }\n",
    "    | prompt\n",
    "    | llm\n",
    "    | OpenAIToolsAgentOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import AgentExecutor\n",
    "\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.callbacks import get_openai_callback\n",
    "quest = \"what are the products that had the most sales in terms of amount in the period of August 2021 to December 2021.\"\n",
    "\n",
    "with get_openai_callback() as cb:\n",
    "    result = list(agent_executor.stream({\"input\": quest}))\n",
    "    table_info = result[-1]['messages'][0].content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"\"\"You are helpful PostgreSQL Query Generator who can write excellent queries using the table schema and demo data provided.\n",
    "               The query should be precise and should be able to retrieve the data so that it answers the users question propely.\n",
    "               Table Info: {tableinfo}\n",
    "\n",
    "               Just output the SQL Query and nothing else.\n",
    "            \"\"\",\n",
    "        ),\n",
    "        (\"user\", \"{input}\")\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = query_prompt | llmoai\n",
    "\n",
    "query = chain.invoke({\n",
    "    'tableinfo': table_info,\n",
    "    'input':quest\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def extract_sql_query(text):\n",
    "    # Regex pattern to match SQL code enclosed between ```sql and ```\n",
    "    pattern = r\"```sql\\s*(.*?)\\s*```\"\n",
    "    match = re.search(pattern, text, re.DOTALL)\n",
    "    \n",
    "    # Return the matched query if found, otherwise None\n",
    "    return match.group(1).strip() if match else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_query = extract_sql_query(query.content)\n",
    "print(sql_query)\n",
    "db.run(sql_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```sql\n",
      "SELECT p.product_name, SUM(od.quantity * p.price) AS total_sales\n",
      "FROM order_details od\n",
      "JOIN orders o ON od.order_id = o.order_id\n",
      "JOIN products p ON od.product_id = p.product_id\n",
      "WHERE o.order_date >= '2021-08-01' AND o.order_date < '2022-01-01'\n",
      "GROUP BY p.product_name\n",
      "ORDER BY total_sales DESC;\n",
      "```\n",
      "\n",
      "No issues were found with using NOT IN with NULL values, UNION, proper quoting of identifiers, correct number of arguments for functions, or casting. However, I did change the BETWEEN operator to exclude the upper bound, as BETWEEN in PostgreSQL is inclusive. Also, I changed the date upper bound to '2022-01-01' to include all orders in December 2021.\n"
     ]
    }
   ],
   "source": [
    "print(checker_tool.invoke(query.content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_groq import ChatGroq\n",
    "llm=ChatGroq(model='llama3-8b-8192')\n",
    "text_to_sql_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\",\n",
    "         \"\"\"You are an expert SQL query generator, for the question asked, output only the sql query and nothing else.\n",
    "            Do not output anything else, strictly output the query only.\n",
    "            Return {top_k} rows only.\n",
    "            Here is the table info {table_info}\n",
    "         \"\"\"),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def extract_sql_query(text):\n",
    "    # Regex pattern to match SQL code enclosed between ```sql and ```\n",
    "    pattern = r\"```sql\\s*(.*?)\\s*```\"\n",
    "    match = re.search(pattern, text, re.DOTALL)\n",
    "    \n",
    "    # Return the matched query if found, otherwise None\n",
    "    return match.group(1).strip() if match else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import create_sql_query_chain\n",
    "from langchain_community.callbacks import get_openai_callback\n",
    "\n",
    "chain = create_sql_query_chain(llmoai, db,text_to_sql_prompt)\n",
    "with get_openai_callback() as cb:\n",
    "    response = chain.invoke({\"question\": \"What are the least sold products in USA\"})\n",
    "result = extract_sql_query(response)\n",
    "print(result)\n",
    "print(cb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db.run(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.sql_database.prompt import SQL_PROMPTS\n",
    "pgprompt = SQL_PROMPTS['postgresql']\n",
    "print(pgprompt.template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.openai_tools import create_extraction_chain_pydantic\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "class Table(BaseModel):\n",
    "    \"\"\"Table in SQL database.\"\"\"\n",
    "\n",
    "    name: str = Field(description=\"Name of table in SQL database.\")\n",
    "\n",
    "\n",
    "table_names = \"\\n\".join(db.get_usable_table_names())\n",
    "system = f\"\"\"Return the names of ALL the SQL tables that MIGHT be relevant to the user question. \\\n",
    "The tables are:\n",
    "\n",
    "{table_names}\n",
    "\n",
    "Remember to include ALL POTENTIALLY RELEVANT tables, even if you're not sure that they're needed.\"\"\"\n",
    "table_chain = create_extraction_chain_pydantic(Table, llmoai, system_message=system)\n",
    "table_chain.invoke({\"input\": \"What are sales in USA\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import itemgetter\n",
    "\n",
    "from langchain.chains import create_sql_query_chain\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "query_chain = create_sql_query_chain(llmoai, db)\n",
    "# Convert \"question\" key to the \"input\" key expected by current table_chain.\n",
    "table_chain = {\"input\": itemgetter(\"question\")} | table_chain\n",
    "# Set table_names_to_use using table_chain.\n",
    "full_chain = RunnablePassthrough.assign(table_names_to_use=table_chain) | query_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = full_chain.invoke(\n",
    "    {\"question\": \"What are the products with most sales in usa and india\"}\n",
    ")\n",
    "print(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.agent_toolkits import create_sql_agent\n",
    "from langchain_community.callbacks import get_openai_callback\n",
    "agent_executor = create_sql_agent(llmoai, db=db, agent_type=\"openai-tools\", verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with get_openai_callback() as cb:\n",
    "    result = agent_executor.invoke(\n",
    "    \"What are the least sold products in USA\"\n",
    ")\n",
    "    print(cb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(result['output'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import Tool\n",
    "from langchain_core.tools import tool\n",
    "\n",
    "\n",
    "def getschema(query: str):\n",
    "\n",
    "    schema = get_schema_tool.invoke(query)\n",
    "\n",
    "    return schema\n",
    "\n",
    "@tool\n",
    "def listtables():\n",
    "    \"\"\"\n",
    "    \n",
    "    Args: Nothing\n",
    "    Output: list of tables available in the database\n",
    "\n",
    "    The tool returns the lists of tables available in the database, there is no input required to invoke this tool. \n",
    "    The tool can be called directly without any input\n",
    "    \n",
    "    \"\"\"\n",
    "    tables = list_tables_tool.invoke(\"\")\n",
    "    return tables\n",
    "\n",
    "\n",
    "schema_tool = Tool(\n",
    "    name=\"Schema Tool\",\n",
    "    func=getschema,\n",
    "    description=\"Returns the schemas of tables, input should be a table name or list of table names\",\n",
    "    return_direct=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema_tool.invoke(\"Customer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "def query_gen_node(state):\n",
    "    print(\"---GENERATE---\")\n",
    "    messages = state[\"messages\"]\n",
    "    question = messages[0].content\n",
    "    last_message = messages[-1]\n",
    "\n",
    "    query_gen_prompt = \"\"\"\n",
    "\n",
    "You are a SQL query generator. Given table schemas and a natural language query, output only the exact SQL query needed - no explanations or additional text. Generate standard SQL that would work in common database systems like PostgreSQL, MySQL, or SQL Server. Consider:\n",
    "\n",
    "Generate the most efficient query to solve the problem\n",
    "Include proper table joins using appropriate join types (INNER, LEFT, etc.)\n",
    "Use appropriate indexes and optimizations when relevant\n",
    "Feel free to use any SQL commands including DML statements (INSERT, UPDATE, DELETE) if the request requires data modification\n",
    "Include any necessary CTEs, subqueries, or window functions\n",
    "Format the query with proper indentation and line breaks for readability\n",
    "\n",
    "Start each query on a new line with no preceding text. End with a semicolon. Do not provide any explanations or notes - output only the SQL query itself\n",
    "\n",
    "Question: {question}\n",
    "Schema: {last_message}\n",
    "\n",
    "\"\"\"\n",
    "    \n",
    "    prompt_template = ChatPromptTemplate.from_template(query_gen_prompt)\n",
    "    # LLM\n",
    "    llm = ChatGroq(model_name=\"llama-3.1-70b-versatile\", temperature=0.5, streaming=True)\n",
    "    query_gen = prompt_template | llm | StrOutputParser()\n",
    "\n",
    "    result = query_gen.invoke({\"question\": question, \"last_message\": last_message})\n",
    "\n",
    "    return {\"messages\": [AIMessage(content=result)] }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated, Sequence\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "from langchain_core.messages import BaseMessage\n",
    "\n",
    "from langgraph.graph.message import add_messages\n",
    "\n",
    "\n",
    "class AgentState(TypedDict):\n",
    "    # The add_messages function defines how an update should be processed\n",
    "    # Default is to replace. add_messages says \"append\"\n",
    "    messages: Annotated[Sequence[BaseMessage], add_messages]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def first_tool_call(state: AgentState) -> dict[str, list[AIMessage]]:\n",
    "    return {\n",
    "        \"messages\": [\n",
    "            AIMessage(\n",
    "                content=\"\",\n",
    "                tool_calls=[\n",
    "                    {\n",
    "                        \"name\": \"sql_db_list_tables\",\n",
    "                        \"args\": {},\n",
    "                        \"id\": \"tool_123\",\n",
    "                    }\n",
    "                ],\n",
    "            )\n",
    "        ]\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import END, StateGraph, START\n",
    "from langgraph.prebuilt import ToolNode\n",
    "workflow = StateGraph(AgentState)\n",
    "\n",
    "schema = ToolNode([schema_tool])\n",
    "tables = ToolNode([listtables])\n",
    "workflow.add_node(\"first_tool_call\", first_tool_call)\n",
    "workflow.add_node(\"getschema\", schema)\n",
    "workflow.add_node(\"tables\",tables)\n",
    "workflow.add_node(\"generatequery\", query_gen_node)\n",
    "\n",
    "workflow.add_edge(START,'first_tool_call')\n",
    "workflow.add_edge('first_tool_call','tables')\n",
    "workflow.add_edge('tables','getschema')\n",
    "workflow.add_edge('getschema','generatequery')\n",
    "workflow.add_edge('generatequery',END)\n",
    "\n",
    "graph = workflow.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "try:\n",
    "    display(Image(graph.get_graph(xray=False).draw_mermaid_png()))\n",
    "except Exception:\n",
    "    # This requires some extra dependencies and is optional\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HIL with SQL Query Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.utilities import SQLDatabase\n",
    "db = SQLDatabase.from_uri(\"postgresql://postgres:642000@localhost:5432/test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "llm=ChatGroq(model='mixtral-8x7b-32768')\n",
    "text_to_sql_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\",\n",
    "         \"\"\"You are an expert SQL query generator, for the question asked, output only the sql query and nothing else.\n",
    "            Do not output anything else, strictly output the query only.\n",
    "            Return {top_k} rows only.\n",
    "            Here is the table info {table_info}\n",
    "         \"\"\"),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "llmoai = ChatOpenAI(model=\"gpt-4o-mini\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "llmgem = ChatGoogleGenerativeAI(model=\"gemini-1.5-flash-001\", temperature=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def extract_sql_query(text):\n",
    "    # Regex pattern to match SQL code enclosed between ```sql and ```\n",
    "    pattern = r\"```sql\\s*(.*?)\\s*```\"\n",
    "    match = re.search(pattern, text, re.DOTALL)\n",
    "    \n",
    "    # Return the matched query if found, otherwise None\n",
    "    return match.group(1).strip() if match else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import create_sql_query_chain\n",
    "\n",
    "sql_chain = create_sql_query_chain(llmgem, db,text_to_sql_prompt)\n",
    "response = sql_chain.invoke({\"question\": \"List the customer who bought most products in terms of money\"})\n",
    "result = extract_sql_query(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(response)\n",
    "print(\"---------------------------\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db.run(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated, Sequence\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "from langchain_core.messages import BaseMessage\n",
    "\n",
    "from langgraph.graph.message import add_messages\n",
    "\n",
    "\n",
    "class AgentState(TypedDict):\n",
    "    # The add_messages function defines how an update should be processed\n",
    "    # Default is to replace. add_messages says \"append\"\n",
    "    messages: Annotated[Sequence[BaseMessage], add_messages]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Nodes\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "def genquery(state):\n",
    "    \"\"\"\n",
    "    Generate the SQL Query for the NL Question\n",
    "\n",
    "    Args:\n",
    "        state (messages): The current state\n",
    "\n",
    "    Returns:\n",
    "         dict: The generated SQL Query\n",
    "    \"\"\"\n",
    "    print(\"---GENERATING SQL QUERY---\")\n",
    "    messages = state[\"messages\"]\n",
    "    question = messages[0].content\n",
    "   \n",
    "    response = sql_chain.invoke(question)\n",
    "    return {\"messages\": [response]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def human_feedback(state):\n",
    "    print(\"---RECEIEVE HUMAN FEEDBACK---\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "compare",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
